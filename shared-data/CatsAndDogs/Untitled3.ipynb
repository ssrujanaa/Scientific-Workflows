{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/optuna/structs.py:21: FutureWarning: `structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "  warnings.warn(_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:118: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 432 samples, validate on 48 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/432 [============================>.] - ETA: 2:16 - loss: 0.9185 - acc: 0.500 - ETA: 1:42 - loss: 1.8639 - acc: 0.500 - ETA: 1:31 - loss: 1.4359 - acc: 0.666 - ETA: 1:23 - loss: 1.0812 - acc: 0.750 - ETA: 1:17 - loss: 0.8670 - acc: 0.800 - ETA: 1:14 - loss: 1.0761 - acc: 0.750 - ETA: 1:12 - loss: 1.0583 - acc: 0.642 - ETA: 1:10 - loss: 1.1688 - acc: 0.625 - ETA: 1:09 - loss: 1.1267 - acc: 0.611 - ETA: 1:08 - loss: 1.0537 - acc: 0.650 - ETA: 1:07 - loss: 1.1871 - acc: 0.590 - ETA: 1:06 - loss: 1.1606 - acc: 0.583 - ETA: 1:05 - loss: 1.1081 - acc: 0.615 - ETA: 1:04 - loss: 1.1821 - acc: 0.571 - ETA: 1:03 - loss: 1.1665 - acc: 0.566 - ETA: 1:02 - loss: 1.1515 - acc: 0.531 - ETA: 1:02 - loss: 1.2024 - acc: 0.500 - ETA: 1:02 - loss: 1.1897 - acc: 0.500 - ETA: 1:01 - loss: 1.1788 - acc: 0.473 - ETA: 1:00 - loss: 1.2398 - acc: 0.450 - ETA: 1:00 - loss: 1.2154 - acc: 0.452 - ETA: 59s - loss: 1.1933 - acc: 0.431 - ETA: 59s - loss: 1.1652 - acc: 0.45 - ETA: 58s - loss: 1.1344 - acc: 0.47 - ETA: 58s - loss: 1.1112 - acc: 0.50 - ETA: 57s - loss: 1.0977 - acc: 0.50 - ETA: 56s - loss: 1.0781 - acc: 0.50 - ETA: 56s - loss: 1.0598 - acc: 0.50 - ETA: 55s - loss: 1.0267 - acc: 0.51 - ETA: 55s - loss: 0.9953 - acc: 0.53 - ETA: 54s - loss: 1.0439 - acc: 0.51 - ETA: 54s - loss: 1.0483 - acc: 0.50 - ETA: 54s - loss: 1.0467 - acc: 0.50 - ETA: 54s - loss: 1.0256 - acc: 0.51 - ETA: 53s - loss: 1.0428 - acc: 0.50 - ETA: 53s - loss: 1.0470 - acc: 0.48 - ETA: 52s - loss: 1.0316 - acc: 0.50 - ETA: 52s - loss: 1.0100 - acc: 0.51 - ETA: 51s - loss: 1.0193 - acc: 0.50 - ETA: 51s - loss: 1.0089 - acc: 0.50 - ETA: 51s - loss: 0.9955 - acc: 0.51 - ETA: 50s - loss: 0.9903 - acc: 0.51 - ETA: 50s - loss: 1.0164 - acc: 0.50 - ETA: 50s - loss: 1.0093 - acc: 0.50 - ETA: 50s - loss: 0.9959 - acc: 0.51 - ETA: 49s - loss: 0.9895 - acc: 0.51 - ETA: 49s - loss: 0.9827 - acc: 0.51 - ETA: 48s - loss: 0.9693 - acc: 0.52 - ETA: 48s - loss: 0.9580 - acc: 0.53 - ETA: 48s - loss: 0.9412 - acc: 0.54 - ETA: 47s - loss: 0.9340 - acc: 0.53 - ETA: 47s - loss: 0.9363 - acc: 0.52 - ETA: 46s - loss: 0.9334 - acc: 0.52 - ETA: 46s - loss: 0.9300 - acc: 0.52 - ETA: 46s - loss: 0.9263 - acc: 0.52 - ETA: 45s - loss: 0.9157 - acc: 0.53 - ETA: 45s - loss: 0.9131 - acc: 0.52 - ETA: 44s - loss: 0.9051 - acc: 0.52 - ETA: 44s - loss: 0.8984 - acc: 0.52 - ETA: 44s - loss: 0.8916 - acc: 0.52 - ETA: 43s - loss: 0.8849 - acc: 0.53 - ETA: 43s - loss: 0.8991 - acc: 0.52 - ETA: 43s - loss: 0.8968 - acc: 0.52 - ETA: 42s - loss: 0.8903 - acc: 0.52 - ETA: 42s - loss: 0.8792 - acc: 0.53 - ETA: 42s - loss: 0.8807 - acc: 0.53 - ETA: 41s - loss: 0.8762 - acc: 0.52 - ETA: 41s - loss: 0.8831 - acc: 0.52 - ETA: 41s - loss: 0.8768 - acc: 0.52 - ETA: 40s - loss: 0.8672 - acc: 0.53 - ETA: 40s - loss: 0.8640 - acc: 0.53 - ETA: 40s - loss: 0.8526 - acc: 0.54 - ETA: 39s - loss: 0.8679 - acc: 0.53 - ETA: 39s - loss: 0.8621 - acc: 0.54 - ETA: 39s - loss: 0.8603 - acc: 0.54 - ETA: 38s - loss: 0.8554 - acc: 0.54 - ETA: 38s - loss: 0.8551 - acc: 0.54 - ETA: 38s - loss: 0.8521 - acc: 0.54 - ETA: 37s - loss: 0.8480 - acc: 0.55 - ETA: 37s - loss: 0.8478 - acc: 0.55 - ETA: 37s - loss: 0.8422 - acc: 0.55 - ETA: 36s - loss: 0.8372 - acc: 0.56 - ETA: 36s - loss: 0.8299 - acc: 0.56 - ETA: 36s - loss: 0.8275 - acc: 0.57 - ETA: 35s - loss: 0.8262 - acc: 0.57 - ETA: 35s - loss: 0.8248 - acc: 0.56 - ETA: 35s - loss: 0.8213 - acc: 0.56 - ETA: 35s - loss: 0.8144 - acc: 0.57 - ETA: 34s - loss: 0.8086 - acc: 0.57 - ETA: 34s - loss: 0.8063 - acc: 0.58 - ETA: 34s - loss: 0.8034 - acc: 0.58 - ETA: 33s - loss: 0.7988 - acc: 0.58 - ETA: 33s - loss: 0.8009 - acc: 0.58 - ETA: 33s - loss: 0.8041 - acc: 0.57 - ETA: 32s - loss: 0.7995 - acc: 0.57 - ETA: 32s - loss: 0.7985 - acc: 0.57 - ETA: 32s - loss: 0.7927 - acc: 0.58 - ETA: 32s - loss: 0.7996 - acc: 0.57 - ETA: 31s - loss: 0.7984 - acc: 0.57 - ETA: 31s - loss: 0.7951 - acc: 0.58 - ETA: 31s - loss: 0.7931 - acc: 0.57 - ETA: 30s - loss: 0.7896 - acc: 0.58 - ETA: 30s - loss: 0.7896 - acc: 0.58 - ETA: 30s - loss: 0.7877 - acc: 0.58 - ETA: 29s - loss: 0.7857 - acc: 0.58 - ETA: 29s - loss: 0.7923 - acc: 0.58 - ETA: 29s - loss: 0.7881 - acc: 0.58 - ETA: 29s - loss: 0.7838 - acc: 0.59 - ETA: 28s - loss: 0.7868 - acc: 0.59 - ETA: 28s - loss: 0.7837 - acc: 0.59 - ETA: 28s - loss: 0.7935 - acc: 0.58 - ETA: 28s - loss: 0.7949 - acc: 0.58 - ETA: 27s - loss: 0.7908 - acc: 0.58 - ETA: 27s - loss: 0.7885 - acc: 0.58 - ETA: 27s - loss: 0.7863 - acc: 0.58 - ETA: 26s - loss: 0.7855 - acc: 0.58 - ETA: 26s - loss: 0.7812 - acc: 0.58 - ETA: 26s - loss: 0.7753 - acc: 0.58 - ETA: 26s - loss: 0.7778 - acc: 0.58 - ETA: 25s - loss: 0.7739 - acc: 0.58 - ETA: 25s - loss: 0.7713 - acc: 0.59 - ETA: 25s - loss: 0.7708 - acc: 0.59 - ETA: 24s - loss: 0.7657 - acc: 0.59 - ETA: 24s - loss: 0.7677 - acc: 0.58 - ETA: 24s - loss: 0.7666 - acc: 0.58 - ETA: 24s - loss: 0.7692 - acc: 0.58 - ETA: 23s - loss: 0.7654 - acc: 0.59 - ETA: 23s - loss: 0.7643 - acc: 0.59 - ETA: 23s - loss: 0.7677 - acc: 0.59 - ETA: 22s - loss: 0.7652 - acc: 0.59 - ETA: 22s - loss: 0.7637 - acc: 0.59 - ETA: 22s - loss: 0.7643 - acc: 0.59 - ETA: 22s - loss: 0.7603 - acc: 0.60 - ETA: 21s - loss: 0.7614 - acc: 0.60 - ETA: 21s - loss: 0.7561 - acc: 0.60 - ETA: 21s - loss: 0.7546 - acc: 0.60 - ETA: 21s - loss: 0.7551 - acc: 0.60 - ETA: 20s - loss: 0.7505 - acc: 0.60 - ETA: 20s - loss: 0.7455 - acc: 0.60 - ETA: 20s - loss: 0.7409 - acc: 0.61 - ETA: 19s - loss: 0.7454 - acc: 0.60 - ETA: 19s - loss: 0.7427 - acc: 0.61 - ETA: 19s - loss: 0.7427 - acc: 0.61 - ETA: 19s - loss: 0.7425 - acc: 0.61 - ETA: 18s - loss: 0.7409 - acc: 0.61 - ETA: 18s - loss: 0.7376 - acc: 0.61 - ETA: 18s - loss: 0.7351 - acc: 0.61 - ETA: 18s - loss: 0.7335 - acc: 0.61 - ETA: 17s - loss: 0.7300 - acc: 0.61 - ETA: 17s - loss: 0.7286 - acc: 0.61 - ETA: 17s - loss: 0.7284 - acc: 0.61 - ETA: 16s - loss: 0.7298 - acc: 0.61 - ETA: 16s - loss: 0.7359 - acc: 0.61 - ETA: 16s - loss: 0.7368 - acc: 0.61 - ETA: 16s - loss: 0.7343 - acc: 0.61 - ETA: 15s - loss: 0.7325 - acc: 0.61 - ETA: 15s - loss: 0.7299 - acc: 0.61 - ETA: 15s - loss: 0.7303 - acc: 0.61 - ETA: 15s - loss: 0.7263 - acc: 0.61 - ETA: 14s - loss: 0.7248 - acc: 0.62 - ETA: 14s - loss: 0.7233 - acc: 0.62 - ETA: 14s - loss: 0.7202 - acc: 0.62 - ETA: 14s - loss: 0.7189 - acc: 0.62 - ETA: 13s - loss: 0.7247 - acc: 0.62 - ETA: 13s - loss: 0.7239 - acc: 0.62 - ETA: 13s - loss: 0.7208 - acc: 0.62 - ETA: 12s - loss: 0.7198 - acc: 0.62 - ETA: 12s - loss: 0.7188 - acc: 0.62 - ETA: 12s - loss: 0.7180 - acc: 0.62 - ETA: 12s - loss: 0.7149 - acc: 0.62 - ETA: 11s - loss: 0.7144 - acc: 0.62 - ETA: 11s - loss: 0.7140 - acc: 0.62 - ETA: 11s - loss: 0.7115 - acc: 0.63 - ETA: 11s - loss: 0.7100 - acc: 0.62 - ETA: 10s - loss: 0.7090 - acc: 0.62 - ETA: 10s - loss: 0.7194 - acc: 0.62 - ETA: 10s - loss: 0.7174 - acc: 0.62 - ETA: 10s - loss: 0.7150 - acc: 0.62 - ETA: 9s - loss: 0.7126 - acc: 0.6313 - ETA: 9s - loss: 0.7099 - acc: 0.633 - ETA: 9s - loss: 0.7104 - acc: 0.632 - ETA: 8s - loss: 0.7125 - acc: 0.631 - ETA: 8s - loss: 0.7105 - acc: 0.633 - ETA: 8s - loss: 0.7105 - acc: 0.633 - ETA: 8s - loss: 0.7101 - acc: 0.632 - ETA: 7s - loss: 0.7083 - acc: 0.634 - ETA: 7s - loss: 0.7070 - acc: 0.633 - ETA: 7s - loss: 0.7043 - acc: 0.635 - ETA: 7s - loss: 0.7025 - acc: 0.637 - ETA: 6s - loss: 0.6992 - acc: 0.639 - ETA: 6s - loss: 0.6964 - acc: 0.641 - ETA: 6s - loss: 0.6972 - acc: 0.640 - ETA: 6s - loss: 0.6970 - acc: 0.639 - ETA: 5s - loss: 0.6981 - acc: 0.639 - ETA: 5s - loss: 0.6972 - acc: 0.638 - ETA: 5s - loss: 0.7024 - acc: 0.635 - ETA: 5s - loss: 0.6989 - acc: 0.637 - ETA: 4s - loss: 0.6992 - acc: 0.636 - ETA: 4s - loss: 0.6968 - acc: 0.638 - ETA: 4s - loss: 0.6955 - acc: 0.640 - ETA: 3s - loss: 0.6941 - acc: 0.639 - ETA: 3s - loss: 0.6909 - acc: 0.641 - ETA: 3s - loss: 0.6882 - acc: 0.642 - ETA: 3s - loss: 0.6851 - acc: 0.644 - ETA: 2s - loss: 0.6899 - acc: 0.641 - ETA: 2s - loss: 0.6878 - acc: 0.643 - ETA: 2s - loss: 0.6873 - acc: 0.642 - ETA: 2s - loss: 0.6846 - acc: 0.644 - ETA: 1s - loss: 0.6845 - acc: 0.643 - ETA: 1s - loss: 0.6827 - acc: 0.645 - ETA: 1s - loss: 0.6799 - acc: 0.646 - ETA: 1s - loss: 0.6788 - acc: 0.646 - ETA: 0s - loss: 0.6776 - acc: 0.645 - ETA: 0s - loss: 0.6755 - acc: 0.6472"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - ETA: 0s - loss: 0.6746 - acc: 0.648 - 63s 145ms/step - loss: 0.6788 - acc: 0.6481 - val_loss: 0.5038 - val_acc: 0.7708\n",
      "\n",
      "Epoch 00001: saving model to cp.ckpt\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/432 [============================>.] - ETA: 53s - loss: 0.1737 - acc: 1.00 - ETA: 53s - loss: 0.0982 - acc: 1.00 - ETA: 53s - loss: 0.1905 - acc: 1.00 - ETA: 53s - loss: 0.5045 - acc: 0.87 - ETA: 52s - loss: 0.5238 - acc: 0.80 - ETA: 52s - loss: 0.5766 - acc: 0.75 - ETA: 52s - loss: 0.5409 - acc: 0.78 - ETA: 52s - loss: 0.5127 - acc: 0.81 - ETA: 52s - loss: 0.4934 - acc: 0.83 - ETA: 51s - loss: 0.4683 - acc: 0.85 - ETA: 51s - loss: 0.4777 - acc: 0.81 - ETA: 51s - loss: 0.4591 - acc: 0.83 - ETA: 51s - loss: 0.4454 - acc: 0.84 - ETA: 50s - loss: 0.4302 - acc: 0.85 - ETA: 50s - loss: 0.4121 - acc: 0.86 - ETA: 50s - loss: 0.3884 - acc: 0.87 - ETA: 50s - loss: 0.4986 - acc: 0.85 - ETA: 49s - loss: 0.4970 - acc: 0.83 - ETA: 49s - loss: 0.5041 - acc: 0.81 - ETA: 49s - loss: 0.5031 - acc: 0.80 - ETA: 49s - loss: 0.5442 - acc: 0.76 - ETA: 49s - loss: 0.5378 - acc: 0.77 - ETA: 48s - loss: 0.5302 - acc: 0.78 - ETA: 48s - loss: 0.5180 - acc: 0.79 - ETA: 48s - loss: 0.5048 - acc: 0.80 - ETA: 48s - loss: 0.5081 - acc: 0.78 - ETA: 48s - loss: 0.5194 - acc: 0.77 - ETA: 47s - loss: 0.5123 - acc: 0.78 - ETA: 47s - loss: 0.5391 - acc: 0.75 - ETA: 47s - loss: 0.5447 - acc: 0.75 - ETA: 46s - loss: 0.5330 - acc: 0.75 - ETA: 46s - loss: 0.5279 - acc: 0.76 - ETA: 46s - loss: 0.5219 - acc: 0.77 - ETA: 46s - loss: 0.5220 - acc: 0.76 - ETA: 46s - loss: 0.5465 - acc: 0.74 - ETA: 45s - loss: 0.5568 - acc: 0.73 - ETA: 45s - loss: 0.5490 - acc: 0.74 - ETA: 45s - loss: 0.5494 - acc: 0.73 - ETA: 45s - loss: 0.5446 - acc: 0.73 - ETA: 44s - loss: 0.5381 - acc: 0.73 - ETA: 44s - loss: 0.5285 - acc: 0.74 - ETA: 44s - loss: 0.5173 - acc: 0.75 - ETA: 44s - loss: 0.5211 - acc: 0.74 - ETA: 44s - loss: 0.5115 - acc: 0.75 - ETA: 43s - loss: 0.5126 - acc: 0.74 - ETA: 43s - loss: 0.5099 - acc: 0.75 - ETA: 43s - loss: 0.5015 - acc: 0.75 - ETA: 43s - loss: 0.4920 - acc: 0.76 - ETA: 42s - loss: 0.5031 - acc: 0.75 - ETA: 42s - loss: 0.5010 - acc: 0.76 - ETA: 42s - loss: 0.5033 - acc: 0.75 - ETA: 42s - loss: 0.5066 - acc: 0.75 - ETA: 41s - loss: 0.5150 - acc: 0.74 - ETA: 41s - loss: 0.5071 - acc: 0.75 - ETA: 41s - loss: 0.4985 - acc: 0.75 - ETA: 41s - loss: 0.5033 - acc: 0.75 - ETA: 40s - loss: 0.4976 - acc: 0.75 - ETA: 40s - loss: 0.5089 - acc: 0.75 - ETA: 40s - loss: 0.5069 - acc: 0.74 - ETA: 39s - loss: 0.5028 - acc: 0.75 - ETA: 39s - loss: 0.4976 - acc: 0.75 - ETA: 39s - loss: 0.4971 - acc: 0.75 - ETA: 39s - loss: 0.4971 - acc: 0.75 - ETA: 38s - loss: 0.5030 - acc: 0.75 - ETA: 38s - loss: 0.4956 - acc: 0.75 - ETA: 38s - loss: 0.4886 - acc: 0.75 - ETA: 38s - loss: 0.5040 - acc: 0.74 - ETA: 37s - loss: 0.5013 - acc: 0.75 - ETA: 37s - loss: 0.4995 - acc: 0.74 - ETA: 37s - loss: 0.4993 - acc: 0.74 - ETA: 37s - loss: 0.4947 - acc: 0.74 - ETA: 36s - loss: 0.4923 - acc: 0.75 - ETA: 36s - loss: 0.4920 - acc: 0.74 - ETA: 36s - loss: 0.4906 - acc: 0.75 - ETA: 36s - loss: 0.4846 - acc: 0.75 - ETA: 35s - loss: 0.4865 - acc: 0.75 - ETA: 35s - loss: 0.4819 - acc: 0.75 - ETA: 35s - loss: 0.4783 - acc: 0.75 - ETA: 35s - loss: 0.4725 - acc: 0.75 - ETA: 34s - loss: 0.4684 - acc: 0.76 - ETA: 34s - loss: 0.4690 - acc: 0.76 - ETA: 34s - loss: 0.4645 - acc: 0.76 - ETA: 34s - loss: 0.4612 - acc: 0.77 - ETA: 33s - loss: 0.4581 - acc: 0.77 - ETA: 33s - loss: 0.4652 - acc: 0.77 - ETA: 33s - loss: 0.4608 - acc: 0.77 - ETA: 33s - loss: 0.4653 - acc: 0.77 - ETA: 32s - loss: 0.4644 - acc: 0.76 - ETA: 32s - loss: 0.4630 - acc: 0.76 - ETA: 32s - loss: 0.4640 - acc: 0.76 - ETA: 32s - loss: 0.4612 - acc: 0.76 - ETA: 31s - loss: 0.4597 - acc: 0.77 - ETA: 31s - loss: 0.4639 - acc: 0.76 - ETA: 31s - loss: 0.4591 - acc: 0.77 - ETA: 31s - loss: 0.4548 - acc: 0.77 - ETA: 30s - loss: 0.4503 - acc: 0.77 - ETA: 30s - loss: 0.4564 - acc: 0.77 - ETA: 30s - loss: 0.4549 - acc: 0.77 - ETA: 30s - loss: 0.4522 - acc: 0.77 - ETA: 29s - loss: 0.4519 - acc: 0.77 - ETA: 29s - loss: 0.4475 - acc: 0.77 - ETA: 29s - loss: 0.4523 - acc: 0.77 - ETA: 29s - loss: 0.4572 - acc: 0.77 - ETA: 28s - loss: 0.4616 - acc: 0.76 - ETA: 28s - loss: 0.4630 - acc: 0.76 - ETA: 28s - loss: 0.4590 - acc: 0.76 - ETA: 28s - loss: 0.4593 - acc: 0.76 - ETA: 27s - loss: 0.4589 - acc: 0.76 - ETA: 27s - loss: 0.4579 - acc: 0.76 - ETA: 27s - loss: 0.4591 - acc: 0.75 - ETA: 27s - loss: 0.4626 - acc: 0.75 - ETA: 26s - loss: 0.4693 - acc: 0.75 - ETA: 26s - loss: 0.4684 - acc: 0.75 - ETA: 26s - loss: 0.4652 - acc: 0.75 - ETA: 26s - loss: 0.4612 - acc: 0.76 - ETA: 25s - loss: 0.4573 - acc: 0.76 - ETA: 25s - loss: 0.4623 - acc: 0.76 - ETA: 25s - loss: 0.4590 - acc: 0.76 - ETA: 25s - loss: 0.4592 - acc: 0.76 - ETA: 24s - loss: 0.4616 - acc: 0.76 - ETA: 24s - loss: 0.4584 - acc: 0.76 - ETA: 24s - loss: 0.4563 - acc: 0.76 - ETA: 24s - loss: 0.4606 - acc: 0.76 - ETA: 23s - loss: 0.4674 - acc: 0.76 - ETA: 23s - loss: 0.4655 - acc: 0.76 - ETA: 23s - loss: 0.4636 - acc: 0.76 - ETA: 22s - loss: 0.4622 - acc: 0.76 - ETA: 22s - loss: 0.4594 - acc: 0.76 - ETA: 22s - loss: 0.4573 - acc: 0.77 - ETA: 22s - loss: 0.4578 - acc: 0.77 - ETA: 21s - loss: 0.4635 - acc: 0.77 - ETA: 21s - loss: 0.4623 - acc: 0.77 - ETA: 21s - loss: 0.4601 - acc: 0.77 - ETA: 21s - loss: 0.4576 - acc: 0.77 - ETA: 20s - loss: 0.4557 - acc: 0.77 - ETA: 20s - loss: 0.4532 - acc: 0.77 - ETA: 20s - loss: 0.4507 - acc: 0.78 - ETA: 20s - loss: 0.4481 - acc: 0.78 - ETA: 19s - loss: 0.4477 - acc: 0.78 - ETA: 19s - loss: 0.4448 - acc: 0.78 - ETA: 19s - loss: 0.4421 - acc: 0.78 - ETA: 19s - loss: 0.4537 - acc: 0.77 - ETA: 18s - loss: 0.4508 - acc: 0.77 - ETA: 18s - loss: 0.4480 - acc: 0.78 - ETA: 18s - loss: 0.4487 - acc: 0.77 - ETA: 18s - loss: 0.4467 - acc: 0.78 - ETA: 17s - loss: 0.4438 - acc: 0.78 - ETA: 17s - loss: 0.4412 - acc: 0.78 - ETA: 17s - loss: 0.4389 - acc: 0.78 - ETA: 17s - loss: 0.4369 - acc: 0.78 - ETA: 16s - loss: 0.4496 - acc: 0.78 - ETA: 16s - loss: 0.4468 - acc: 0.78 - ETA: 16s - loss: 0.4449 - acc: 0.78 - ETA: 16s - loss: 0.4448 - acc: 0.78 - ETA: 15s - loss: 0.4431 - acc: 0.78 - ETA: 15s - loss: 0.4429 - acc: 0.78 - ETA: 15s - loss: 0.4404 - acc: 0.78 - ETA: 15s - loss: 0.4378 - acc: 0.78 - ETA: 14s - loss: 0.4370 - acc: 0.78 - ETA: 14s - loss: 0.4350 - acc: 0.79 - ETA: 14s - loss: 0.4330 - acc: 0.79 - ETA: 14s - loss: 0.4308 - acc: 0.79 - ETA: 13s - loss: 0.4291 - acc: 0.79 - ETA: 13s - loss: 0.4283 - acc: 0.79 - ETA: 13s - loss: 0.4267 - acc: 0.79 - ETA: 13s - loss: 0.4373 - acc: 0.79 - ETA: 12s - loss: 0.4367 - acc: 0.79 - ETA: 12s - loss: 0.4344 - acc: 0.79 - ETA: 12s - loss: 0.4331 - acc: 0.79 - ETA: 11s - loss: 0.4320 - acc: 0.79 - ETA: 11s - loss: 0.4302 - acc: 0.79 - ETA: 11s - loss: 0.4327 - acc: 0.79 - ETA: 11s - loss: 0.4319 - acc: 0.79 - ETA: 10s - loss: 0.4298 - acc: 0.79 - ETA: 10s - loss: 0.4311 - acc: 0.79 - ETA: 10s - loss: 0.4327 - acc: 0.79 - ETA: 10s - loss: 0.4303 - acc: 0.79 - ETA: 9s - loss: 0.4312 - acc: 0.7949 - ETA: 9s - loss: 0.4298 - acc: 0.796 - ETA: 9s - loss: 0.4283 - acc: 0.797 - ETA: 9s - loss: 0.4280 - acc: 0.798 - ETA: 8s - loss: 0.4259 - acc: 0.799 - ETA: 8s - loss: 0.4238 - acc: 0.800 - ETA: 8s - loss: 0.4242 - acc: 0.801 - ETA: 8s - loss: 0.4228 - acc: 0.802 - ETA: 7s - loss: 0.4205 - acc: 0.803 - ETA: 7s - loss: 0.4340 - acc: 0.799 - ETA: 7s - loss: 0.4345 - acc: 0.797 - ETA: 7s - loss: 0.4331 - acc: 0.798 - ETA: 6s - loss: 0.4317 - acc: 0.800 - ETA: 6s - loss: 0.4342 - acc: 0.798 - ETA: 6s - loss: 0.4323 - acc: 0.799 - ETA: 5s - loss: 0.4315 - acc: 0.800 - ETA: 5s - loss: 0.4307 - acc: 0.801 - ETA: 5s - loss: 0.4302 - acc: 0.802 - ETA: 5s - loss: 0.4283 - acc: 0.803 - ETA: 4s - loss: 0.4282 - acc: 0.804 - ETA: 4s - loss: 0.4261 - acc: 0.805 - ETA: 4s - loss: 0.4259 - acc: 0.806 - ETA: 4s - loss: 0.4238 - acc: 0.807 - ETA: 3s - loss: 0.4252 - acc: 0.806 - ETA: 3s - loss: 0.4237 - acc: 0.806 - ETA: 3s - loss: 0.4224 - acc: 0.807 - ETA: 3s - loss: 0.4285 - acc: 0.806 - ETA: 2s - loss: 0.4284 - acc: 0.807 - ETA: 2s - loss: 0.4265 - acc: 0.808 - ETA: 2s - loss: 0.4248 - acc: 0.809 - ETA: 2s - loss: 0.4258 - acc: 0.807 - ETA: 1s - loss: 0.4275 - acc: 0.806 - ETA: 1s - loss: 0.4312 - acc: 0.804 - ETA: 1s - loss: 0.4304 - acc: 0.805 - ETA: 1s - loss: 0.4286 - acc: 0.806 - ETA: 0s - loss: 0.4283 - acc: 0.807 - ETA: 0s - loss: 0.4273 - acc: 0.808 - ETA: 0s - loss: 0.4305 - acc: 0.8070"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 62s 144ms/step - loss: 0.4286 - acc: 0.8079 - val_loss: 0.9003 - val_acc: 0.5625\n",
      "\n",
      "Epoch 00002: saving model to cp.ckpt\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/432 [============================>.] - ETA: 54s - loss: 0.9570 - acc: 0.50 - ETA: 56s - loss: 0.5607 - acc: 0.75 - ETA: 55s - loss: 0.5694 - acc: 0.66 - ETA: 54s - loss: 0.4738 - acc: 0.75 - ETA: 54s - loss: 0.3864 - acc: 0.80 - ETA: 54s - loss: 0.3485 - acc: 0.83 - ETA: 54s - loss: 0.3202 - acc: 0.85 - ETA: 54s - loss: 0.4418 - acc: 0.81 - ETA: 54s - loss: 0.4942 - acc: 0.77 - ETA: 53s - loss: 0.4630 - acc: 0.80 - ETA: 53s - loss: 0.4245 - acc: 0.81 - ETA: 52s - loss: 0.3915 - acc: 0.83 - ETA: 52s - loss: 0.3910 - acc: 0.84 - ETA: 52s - loss: 0.3965 - acc: 0.82 - ETA: 52s - loss: 0.3902 - acc: 0.83 - ETA: 52s - loss: 0.3710 - acc: 0.84 - ETA: 51s - loss: 0.3772 - acc: 0.82 - ETA: 51s - loss: 0.3570 - acc: 0.83 - ETA: 51s - loss: 0.3412 - acc: 0.84 - ETA: 50s - loss: 0.3589 - acc: 0.82 - ETA: 50s - loss: 0.3595 - acc: 0.80 - ETA: 50s - loss: 0.4034 - acc: 0.77 - ETA: 49s - loss: 0.4012 - acc: 0.78 - ETA: 49s - loss: 0.4388 - acc: 0.75 - ETA: 49s - loss: 0.4335 - acc: 0.76 - ETA: 49s - loss: 0.4277 - acc: 0.76 - ETA: 48s - loss: 0.4157 - acc: 0.77 - ETA: 48s - loss: 0.4158 - acc: 0.78 - ETA: 48s - loss: 0.4171 - acc: 0.79 - ETA: 48s - loss: 0.4045 - acc: 0.80 - ETA: 47s - loss: 0.4041 - acc: 0.80 - ETA: 47s - loss: 0.3974 - acc: 0.81 - ETA: 47s - loss: 0.3940 - acc: 0.81 - ETA: 47s - loss: 0.3843 - acc: 0.82 - ETA: 46s - loss: 0.3746 - acc: 0.82 - ETA: 46s - loss: 0.3661 - acc: 0.83 - ETA: 46s - loss: 0.3727 - acc: 0.82 - ETA: 46s - loss: 0.3765 - acc: 0.82 - ETA: 45s - loss: 0.3866 - acc: 0.82 - ETA: 45s - loss: 0.3953 - acc: 0.81 - ETA: 45s - loss: 0.3998 - acc: 0.80 - ETA: 45s - loss: 0.3911 - acc: 0.80 - ETA: 45s - loss: 0.3935 - acc: 0.80 - ETA: 44s - loss: 0.3854 - acc: 0.80 - ETA: 44s - loss: 0.3815 - acc: 0.81 - ETA: 44s - loss: 0.3759 - acc: 0.81 - ETA: 44s - loss: 0.3734 - acc: 0.81 - ETA: 43s - loss: 0.3656 - acc: 0.82 - ETA: 43s - loss: 0.3690 - acc: 0.81 - ETA: 43s - loss: 0.3675 - acc: 0.82 - ETA: 42s - loss: 0.3605 - acc: 0.82 - ETA: 42s - loss: 0.3549 - acc: 0.82 - ETA: 42s - loss: 0.3733 - acc: 0.82 - ETA: 42s - loss: 0.3791 - acc: 0.81 - ETA: 41s - loss: 0.3769 - acc: 0.81 - ETA: 41s - loss: 0.3735 - acc: 0.82 - ETA: 41s - loss: 0.3694 - acc: 0.82 - ETA: 40s - loss: 0.3641 - acc: 0.82 - ETA: 40s - loss: 0.3603 - acc: 0.83 - ETA: 40s - loss: 0.3554 - acc: 0.83 - ETA: 40s - loss: 0.3510 - acc: 0.83 - ETA: 39s - loss: 0.3458 - acc: 0.83 - ETA: 39s - loss: 0.3415 - acc: 0.84 - ETA: 39s - loss: 0.3379 - acc: 0.84 - ETA: 39s - loss: 0.3337 - acc: 0.84 - ETA: 38s - loss: 0.3461 - acc: 0.84 - ETA: 38s - loss: 0.3751 - acc: 0.82 - ETA: 38s - loss: 0.3705 - acc: 0.83 - ETA: 38s - loss: 0.3653 - acc: 0.83 - ETA: 37s - loss: 0.3613 - acc: 0.83 - ETA: 37s - loss: 0.3571 - acc: 0.83 - ETA: 37s - loss: 0.3561 - acc: 0.84 - ETA: 36s - loss: 0.3527 - acc: 0.84 - ETA: 36s - loss: 0.3544 - acc: 0.84 - ETA: 36s - loss: 0.3497 - acc: 0.84 - ETA: 36s - loss: 0.3593 - acc: 0.84 - ETA: 35s - loss: 0.3561 - acc: 0.84 - ETA: 35s - loss: 0.3517 - acc: 0.84 - ETA: 35s - loss: 0.3534 - acc: 0.84 - ETA: 35s - loss: 0.3577 - acc: 0.83 - ETA: 34s - loss: 0.3686 - acc: 0.83 - ETA: 34s - loss: 0.3665 - acc: 0.83 - ETA: 34s - loss: 0.3626 - acc: 0.83 - ETA: 34s - loss: 0.3620 - acc: 0.83 - ETA: 33s - loss: 0.3583 - acc: 0.84 - ETA: 33s - loss: 0.3610 - acc: 0.83 - ETA: 33s - loss: 0.3602 - acc: 0.83 - ETA: 33s - loss: 0.3599 - acc: 0.84 - ETA: 32s - loss: 0.3835 - acc: 0.83 - ETA: 32s - loss: 0.3936 - acc: 0.82 - ETA: 32s - loss: 0.3897 - acc: 0.82 - ETA: 32s - loss: 0.3876 - acc: 0.83 - ETA: 31s - loss: 0.3867 - acc: 0.83 - ETA: 31s - loss: 0.3867 - acc: 0.82 - ETA: 31s - loss: 0.3830 - acc: 0.83 - ETA: 31s - loss: 0.3795 - acc: 0.83 - ETA: 30s - loss: 0.3796 - acc: 0.83 - ETA: 30s - loss: 0.3796 - acc: 0.83 - ETA: 30s - loss: 0.3805 - acc: 0.83 - ETA: 29s - loss: 0.3781 - acc: 0.84 - ETA: 29s - loss: 0.3824 - acc: 0.83 - ETA: 29s - loss: 0.3797 - acc: 0.83 - ETA: 29s - loss: 0.3780 - acc: 0.83 - ETA: 28s - loss: 0.3757 - acc: 0.84 - ETA: 28s - loss: 0.3821 - acc: 0.83 - ETA: 28s - loss: 0.3822 - acc: 0.83 - ETA: 28s - loss: 0.3832 - acc: 0.83 - ETA: 27s - loss: 0.3834 - acc: 0.82 - ETA: 27s - loss: 0.3811 - acc: 0.83 - ETA: 27s - loss: 0.3820 - acc: 0.83 - ETA: 27s - loss: 0.3800 - acc: 0.83 - ETA: 26s - loss: 0.3982 - acc: 0.82 - ETA: 26s - loss: 0.4050 - acc: 0.82 - ETA: 26s - loss: 0.4020 - acc: 0.82 - ETA: 26s - loss: 0.3990 - acc: 0.82 - ETA: 25s - loss: 0.3959 - acc: 0.82 - ETA: 25s - loss: 0.3944 - acc: 0.82 - ETA: 25s - loss: 0.3911 - acc: 0.83 - ETA: 25s - loss: 0.3909 - acc: 0.82 - ETA: 24s - loss: 0.3877 - acc: 0.82 - ETA: 24s - loss: 0.3868 - acc: 0.83 - ETA: 24s - loss: 0.3847 - acc: 0.83 - ETA: 24s - loss: 0.3844 - acc: 0.82 - ETA: 23s - loss: 0.3823 - acc: 0.83 - ETA: 23s - loss: 0.3853 - acc: 0.82 - ETA: 23s - loss: 0.3832 - acc: 0.82 - ETA: 23s - loss: 0.3809 - acc: 0.83 - ETA: 22s - loss: 0.3789 - acc: 0.83 - ETA: 22s - loss: 0.3768 - acc: 0.83 - ETA: 22s - loss: 0.3739 - acc: 0.83 - ETA: 22s - loss: 0.3712 - acc: 0.83 - ETA: 21s - loss: 0.3706 - acc: 0.83 - ETA: 21s - loss: 0.3716 - acc: 0.83 - ETA: 21s - loss: 0.3889 - acc: 0.82 - ETA: 21s - loss: 0.3889 - acc: 0.82 - ETA: 20s - loss: 0.3861 - acc: 0.82 - ETA: 20s - loss: 0.3905 - acc: 0.82 - ETA: 20s - loss: 0.3880 - acc: 0.82 - ETA: 20s - loss: 0.3884 - acc: 0.82 - ETA: 19s - loss: 0.3865 - acc: 0.82 - ETA: 19s - loss: 0.3849 - acc: 0.82 - ETA: 19s - loss: 0.3856 - acc: 0.82 - ETA: 19s - loss: 0.3864 - acc: 0.82 - ETA: 18s - loss: 0.3839 - acc: 0.82 - ETA: 18s - loss: 0.3824 - acc: 0.82 - ETA: 18s - loss: 0.3821 - acc: 0.82 - ETA: 18s - loss: 0.3821 - acc: 0.82 - ETA: 17s - loss: 0.3800 - acc: 0.82 - ETA: 17s - loss: 0.3776 - acc: 0.82 - ETA: 17s - loss: 0.3773 - acc: 0.83 - ETA: 16s - loss: 0.3750 - acc: 0.83 - ETA: 16s - loss: 0.3752 - acc: 0.83 - ETA: 16s - loss: 0.3728 - acc: 0.83 - ETA: 16s - loss: 0.3719 - acc: 0.83 - ETA: 15s - loss: 0.3695 - acc: 0.83 - ETA: 15s - loss: 0.3674 - acc: 0.83 - ETA: 15s - loss: 0.3652 - acc: 0.83 - ETA: 15s - loss: 0.3642 - acc: 0.83 - ETA: 14s - loss: 0.3625 - acc: 0.83 - ETA: 14s - loss: 0.3603 - acc: 0.84 - ETA: 14s - loss: 0.3598 - acc: 0.84 - ETA: 14s - loss: 0.3576 - acc: 0.84 - ETA: 13s - loss: 0.3695 - acc: 0.84 - ETA: 13s - loss: 0.3673 - acc: 0.84 - ETA: 13s - loss: 0.3688 - acc: 0.83 - ETA: 13s - loss: 0.3682 - acc: 0.84 - ETA: 12s - loss: 0.3661 - acc: 0.84 - ETA: 12s - loss: 0.3650 - acc: 0.84 - ETA: 12s - loss: 0.3632 - acc: 0.84 - ETA: 12s - loss: 0.3627 - acc: 0.84 - ETA: 11s - loss: 0.3613 - acc: 0.84 - ETA: 11s - loss: 0.3602 - acc: 0.84 - ETA: 11s - loss: 0.3590 - acc: 0.84 - ETA: 11s - loss: 0.3570 - acc: 0.84 - ETA: 10s - loss: 0.3551 - acc: 0.84 - ETA: 10s - loss: 0.3531 - acc: 0.84 - ETA: 10s - loss: 0.3521 - acc: 0.85 - ETA: 9s - loss: 0.3546 - acc: 0.8483 - ETA: 9s - loss: 0.3526 - acc: 0.849 - ETA: 9s - loss: 0.3570 - acc: 0.847 - ETA: 9s - loss: 0.3578 - acc: 0.845 - ETA: 8s - loss: 0.3561 - acc: 0.846 - ETA: 8s - loss: 0.3546 - acc: 0.847 - ETA: 8s - loss: 0.3528 - acc: 0.847 - ETA: 8s - loss: 0.3525 - acc: 0.848 - ETA: 7s - loss: 0.3507 - acc: 0.849 - ETA: 7s - loss: 0.3516 - acc: 0.850 - ETA: 7s - loss: 0.3524 - acc: 0.848 - ETA: 7s - loss: 0.3509 - acc: 0.849 - ETA: 6s - loss: 0.3508 - acc: 0.850 - ETA: 6s - loss: 0.3508 - acc: 0.850 - ETA: 6s - loss: 0.3513 - acc: 0.849 - ETA: 6s - loss: 0.3509 - acc: 0.849 - ETA: 5s - loss: 0.3491 - acc: 0.850 - ETA: 5s - loss: 0.3498 - acc: 0.848 - ETA: 5s - loss: 0.3482 - acc: 0.849 - ETA: 4s - loss: 0.3476 - acc: 0.850 - ETA: 4s - loss: 0.3462 - acc: 0.851 - ETA: 4s - loss: 0.3446 - acc: 0.851 - ETA: 4s - loss: 0.3431 - acc: 0.852 - ETA: 3s - loss: 0.3445 - acc: 0.850 - ETA: 3s - loss: 0.3448 - acc: 0.851 - ETA: 3s - loss: 0.3434 - acc: 0.852 - ETA: 3s - loss: 0.3429 - acc: 0.852 - ETA: 2s - loss: 0.3412 - acc: 0.853 - ETA: 2s - loss: 0.3402 - acc: 0.854 - ETA: 2s - loss: 0.3395 - acc: 0.855 - ETA: 2s - loss: 0.3385 - acc: 0.855 - ETA: 1s - loss: 0.3409 - acc: 0.854 - ETA: 1s - loss: 0.3393 - acc: 0.854 - ETA: 1s - loss: 0.3378 - acc: 0.855 - ETA: 1s - loss: 0.3512 - acc: 0.851 - ETA: 0s - loss: 0.3544 - acc: 0.849 - ETA: 0s - loss: 0.3537 - acc: 0.850 - ETA: 0s - loss: 0.3532 - acc: 0.8512"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 63s 146ms/step - loss: 0.3517 - acc: 0.8519 - val_loss: 0.3038 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00003: saving model to cp.ckpt\n",
      "120/120 [==============================] - ETA: 24 - ETA: 19 - ETA: 18 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 16s 132ms/step\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "import sys\n",
    "import pickle\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input,Dense,BatchNormalization,Flatten,Dropout,GlobalAveragePooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import layer_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model,load_model\n",
    "\n",
    "optuna_csv = sys.argv[1]\n",
    "\n",
    "with open('training.pkl', 'rb') as f:\n",
    "     train = pickle.load(f)\n",
    "    \n",
    "with open('testing.pkl', 'rb') as f:\n",
    "     test = pickle.load(f)\n",
    "        \n",
    "with open('validation.pkl','rb') as f:\n",
    "     val = pickle.load(f)\n",
    "        \n",
    "train_photos, train_labels = list(), list()\n",
    "tp = list()\n",
    "for file in train:\n",
    "    if 'Cat' in file:\n",
    "        output = 1.0\n",
    "    else:\n",
    "        output = 0.0\n",
    "    photo = load_img(file)\n",
    "    photo = img_to_array(photo)\n",
    "    train_photos.append(photo)\n",
    "    train_labels.append(output)\n",
    "train_photos = asarray(train_photos)\n",
    "train_labels = asarray(train_labels)\n",
    "\n",
    "test_photos, test_labels = list(), list()\n",
    "for file in test:\n",
    "    if 'Cat' in file:\n",
    "        output = 1.0\n",
    "    else:\n",
    "        output = 0.0\n",
    "    photo = load_img(file)\n",
    "    photo = img_to_array(photo)\n",
    "    tp.append(photo)\n",
    "    test_photos.append(photo)\n",
    "    test_labels.append(output)\n",
    "test_photos = asarray(test_photos)\n",
    "test_labels = asarray(test_labels)\n",
    "\n",
    "val_photos, val_labels = list(), list()\n",
    "for file in val:\n",
    "    if 'Cat' in file:\n",
    "        output = 1.0\n",
    "    else:\n",
    "        output = 0.0\n",
    "    photo = load_img(file)\n",
    "    photo = img_to_array(photo)\n",
    "    val_photos.append(photo)\n",
    "    val_labels.append(output)\n",
    "val_photos = asarray(val_photos)\n",
    "val_labels = asarray(val_labels)\n",
    "\n",
    "train_photos =train_photos.astype('float32')\n",
    "test_photos= test_photos.astype('float32')\n",
    "val_photos =val_photos.astype('float32')\n",
    "train_photos /= 255\n",
    "val_photos /= 255\n",
    "test_photos /= 255\n",
    "\n",
    "\n",
    "from optkeras.optkeras import OptKeras\n",
    "import optkeras\n",
    "import pickle\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input,Dense,BatchNormalization,Flatten,Dropout,GlobalAveragePooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import layer_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model,load_model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import optuna\n",
    "import os\n",
    "import tensorflow as tf\n",
    "checkpoint_path = \"cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "nb_classes = 2\n",
    "epochs=3\n",
    "batch_size =2\n",
    "\n",
    "vgg16_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "x = vgg16_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(nb_classes, activation = 'softmax')(x)\n",
    "model = Model(input = vgg16_model.input, output = predictions)\n",
    "\n",
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(optimizer = 'rmsprop',loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    period=1)\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "model_info = model.fit(x=train_photos, y=train_labels,batch_size=2 , epochs=epochs,callbacks=[cp_callback], \n",
    "                   verbose=1,validation_data=(val_photos,val_labels))\n",
    "\n",
    "model.save('model_hpo.h5')\n",
    "\n",
    "m= load_model(\"model_hpo.h5\")\n",
    "test_photos = test_photos.astype(\"float32\")\n",
    "\n",
    "results = m.evaluate(test_photos, test_labels, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_checkpoint(study,model,optimizer,current_metrics, checkpoints_files, losses_dict,trial,model_name):\n",
    "#     model_state_dict = {}\n",
    "\n",
    "#     if model_name in PRETRAINED_MODELS.keys():\n",
    "#         whole_state_dict = model.state_dict()\n",
    "#         all_keys = list(whole_state_dict.keys())\n",
    "#         classifier_keys = all_keys[PRETRAINED_MODELS[model_name]:]\n",
    "\n",
    "#         for k,v in whole_state_dict.items():\n",
    "#             if k in classifier_keys:\n",
    "#                 model_state_dict[k] = v\n",
    "#     else:\n",
    "#         model_state_dict = model.state_dict()\n",
    "\n",
    "#     filename='chckpnt_trial_' + str(trial.number) +'_epoch_'+ str(current_metrics[0])+\"_\"+ model_name +'.pth'\n",
    "#     checkpoint = { 'trail': trial.number,\n",
    "#                  'run_parameters': str(trial.params),\n",
    "#                  'curr_epoch': current_metrics[0],\n",
    "#                  'model_state_dict' : model_state_dict,\n",
    "#                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                  'checkpoints_list': checkpoints_files,\n",
    "#                  'train_loss': current_metrics[1],\n",
    "#                  'test_loss': current_metrics[2],\n",
    "#                  'test_accuracy': current_metrics[3],\n",
    "#                  'losses_dict': losses_dict,\n",
    "#                  'optuna_study':study\n",
    "#     }\n",
    "\n",
    "#     checkpoints_files.append(filename)\n",
    "#     torch.save(checkpoint, filename)\n",
    "#     return checkpoints_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(checkpoint_path)\n",
    "# loss,acc = model.evaluate(test_photos,  test_labels, verbose=0)\n",
    "# print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-10 12:45:35,570] A new study created in memory with name: CatsAndDogs_Simple\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-10 12:45:35.578116] [OptKeras] Ready for optimization. (message printed as verbose is set to 1+)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "optkeras.optkeras.get_trial_default = lambda: optuna.trial.FrozenTrial(\n",
    "            None, None, None, None, None, None, None, None, None, None, None)\n",
    "study_name = \"CatsAndDogs\" + '_Simple'\n",
    "ok = OptKeras(study_name=study_name,\n",
    "              monitor='val_acc',\n",
    "              direction='maximize')\n",
    "import joblib\n",
    "MODEL = \"vgg\"\n",
    "STUDY = None\n",
    "N_TRIALS = 3\n",
    "\n",
    "\n",
    "def sigterm_handler(signum, frame):\n",
    "    hpo_monitor_sigterm()\n",
    "    sys.exit(3)\n",
    "    \n",
    "def hpo_monitor(study, trial):\n",
    "    joblib.dump(study,\"study_checkpoint_\" + MODEL + \".pkl\")   \n",
    "    \n",
    "def objective(trial):\n",
    "    nb_classes = 2\n",
    "    epochs=3\n",
    "    batch_size =2\n",
    "    optimizer_options = [\"RMSprop\", \"Adam\", \"SGD\"]\n",
    "\n",
    "    vgg16_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "    x = vgg16_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation=trial.suggest_categorical('activation', ['relu', 'linear']))(x)\n",
    "    predictions = Dense(nb_classes, activation = 'softmax')(x)\n",
    "    model = Model(input = vgg16_model.input, output = predictions)\n",
    "    for layer in vgg16_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer = trial.suggest_categorical(\"optimizer\", [\"rmsprop\", \"Adam\", \"SGD\"]),loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    period=10)\n",
    "    model.fit(x=train_photos, y=train_labels,batch_size=2 , epochs=epochs, callbacks=ok.callbacks(trial),\n",
    "              verbose=ok.keras_verbose ,validation_data=(val_photos,val_labels))\n",
    "    return ok.trial_best_value\n",
    "\n",
    "checkpoint_file = \"study_checkpoint_vgg.pkl\"\n",
    "\n",
    "try:\n",
    "    STUDY = joblib.load(checkpoint_file)\n",
    "    finished = len(STUDY.trials_dataframe())\n",
    "except AttributeError:\n",
    "    STUDY = OptKeras(study_name=study_name,monitor='val_acc',direction='maximize')\n",
    "    finished = 1\n",
    "\n",
    "\n",
    "if finished < N_TRIALS:  \n",
    "    todo_trials = N_TRIALS - finished\n",
    "    if todo_trials > 0 :\n",
    "        STUDY.optimize(objective, n_trials=todo_trials, timeout=600, callbacks=[hpo_monitor])\n",
    "    else:\n",
    "        pass\n",
    "else:\n",
    "    STUDY = OptKeras(study_name=study_name,monitor='val_acc',direction='maximize')\n",
    "    STUDY.optimize(objective, n_trials=N_TRIALS, timeout=600, callbacks=[hpo_monitor])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_activation</th>\n",
       "      <th>params_optimizer</th>\n",
       "      <th>user_attrs__Datetime_epoch_begin</th>\n",
       "      <th>user_attrs__Datetime_epoch_end</th>\n",
       "      <th>user_attrs__Trial_num</th>\n",
       "      <th>user_attrs_acc</th>\n",
       "      <th>user_attrs_loss</th>\n",
       "      <th>user_attrs_val_acc</th>\n",
       "      <th>user_attrs_val_loss</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2020-09-10 10:38:04.364084</td>\n",
       "      <td>2020-09-10 10:41:17.425286</td>\n",
       "      <td>0 days 00:03:13.061202</td>\n",
       "      <td>linear</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>2020-09-10 10:40:10.220480</td>\n",
       "      <td>2020-09-10 10:41:17.036755</td>\n",
       "      <td>0</td>\n",
       "      <td>0.840278</td>\n",
       "      <td>0.371861</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.281831</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>2020-09-10 10:41:17.433711</td>\n",
       "      <td>2020-09-10 10:44:40.778047</td>\n",
       "      <td>0 days 00:03:23.344336</td>\n",
       "      <td>relu</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2020-09-10 10:43:33.169837</td>\n",
       "      <td>2020-09-10 10:44:40.773838</td>\n",
       "      <td>1</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.336904</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.509749</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number     value             datetime_start          datetime_complete  \\\n",
       "0       0  0.875000 2020-09-10 10:38:04.364084 2020-09-10 10:41:17.425286   \n",
       "1       1  0.729167 2020-09-10 10:41:17.433711 2020-09-10 10:44:40.778047   \n",
       "\n",
       "                duration params_activation params_optimizer  \\\n",
       "0 0 days 00:03:13.061202            linear          rmsprop   \n",
       "1 0 days 00:03:23.344336              relu             Adam   \n",
       "\n",
       "  user_attrs__Datetime_epoch_begin user_attrs__Datetime_epoch_end  \\\n",
       "0       2020-09-10 10:40:10.220480     2020-09-10 10:41:17.036755   \n",
       "1       2020-09-10 10:43:33.169837     2020-09-10 10:44:40.773838   \n",
       "\n",
       "   user_attrs__Trial_num  user_attrs_acc  user_attrs_loss  user_attrs_val_acc  \\\n",
       "0                      0        0.840278         0.371861            0.875000   \n",
       "1                      1        0.854167         0.336904            0.729167   \n",
       "\n",
       "   user_attrs_val_loss     state  \n",
       "0             0.281831  COMPLETE  \n",
       "1             0.509749  COMPLETE  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpo_checkpoint_file = \"study_checkpoint_\" + MODEL + \".pkl\"\n",
    "k = joblib.load(hpo_checkpoint_file)\n",
    "k.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'trials_dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-6fa4c7bfda75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mSTUDY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mfinished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTUDY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# except FileNotFoundError:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'trials_dataframe'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "if not os.path.isfile(\"checkpoint_vgg.pkl\"):\n",
    "    with open(\"checkpoint_vgg.pkl\",'wb') as file:\n",
    "        pickle.dump(\"0\", file)\n",
    "        \n",
    "checkpoint_file = \"checkpoint_vgg.pkl\"\n",
    "\n",
    "# try:\n",
    "STUDY = joblib.load(checkpoint_file)\n",
    "finished = len(STUDY.trials_dataframe())\n",
    "# except FileNotFoundError:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    signal.signal(signal.SIGTERM, sigterm_handler)\n",
    "    args     = parser.parse_args()\n",
    "    N_TRIALS = args.trials[0]\n",
    "    MODEL = \"vgg16\"\n",
    "    hpo_checkpoint_file = \"study_checkpoint_\" + MODEL + \".pkl\"\n",
    "    create_study(hpo_checkpoint_file)\n",
    "\n",
    "except Exception as e:\n",
    "    pass\n",
    "finally:\n",
    "    hpo_monitor_sigterm(\"final_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] num_trials\n",
      "ipykernel_launcher.py: error: argument num_trials: invalid int value: '/home/scitech/.local/share/jupyter/runtime/kernel-515b4e2f-033d-41a9-934f-471f4b3125d7.json'\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/argparse.py\", line 2294, in _get_value\n",
      "    result = type_func(arg_string)\n",
      "ValueError: invalid literal for int() with base 10: '/home/scitech/.local/share/jupyter/runtime/kernel-515b4e2f-033d-41a9-934f-471f4b3125d7.json'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/argparse.py\", line 1766, in parse_known_args\n",
      "    namespace, args = self._parse_known_args(args, namespace)\n",
      "  File \"/usr/lib64/python3.6/argparse.py\", line 1975, in _parse_known_args\n",
      "    stop_index = consume_positionals(start_index)\n",
      "  File \"/usr/lib64/python3.6/argparse.py\", line 1931, in consume_positionals\n",
      "    take_action(action, args)\n",
      "  File \"/usr/lib64/python3.6/argparse.py\", line 1824, in take_action\n",
      "    argument_values = self._get_values(action, argument_strings)\n",
      "  File \"/usr/lib64/python3.6/argparse.py\", line 2279, in _get_values\n",
      "    value = [self._get_value(action, v) for v in arg_strings]\n",
      "  File \"/usr/lib64/python3.6/argparse.py\", line 2279, in <listcomp>\n",
      "    value = [self._get_value(action, v) for v in arg_strings]\n",
      "  File \"/usr/lib64/python3.6/argparse.py\", line 2307, in _get_value\n",
      "    raise ArgumentError(action, msg % args)\n",
      "argparse.ArgumentError: argument num_trials: invalid int value: '/home/scitech/.local/share/jupyter/runtime/kernel-515b4e2f-033d-41a9-934f-471f4b3125d7.json'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-26-50d4f9e8d341>\", line 27, in <module>\n",
      "    main()\n",
      "  File \"<ipython-input-26-50d4f9e8d341>\", line 14, in main\n",
      "    args     = parser.parse_args()\n",
      "  File \"/usr/lib64/python3.6/argparse.py\", line 1734, in parse_args\n",
      "    args, argv = self.parse_known_args(args, namespace)\n",
      "  File \"/usr/lib64/python3.6/argparse.py\", line 1773, in parse_known_args\n",
      "    self.error(str(err))\n",
      "  File \"/usr/lib64/python3.6/argparse.py\", line 2393, in error\n",
      "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
      "  File \"/usr/lib64/python3.6/argparse.py\", line 2380, in exit\n",
      "    _sys.exit(status)\n",
      "SystemExit: 2\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib64/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib64/python3.6/argparse.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, action, arg_string)\u001b[0m\n\u001b[1;32m   2293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2294\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '/home/scitech/.local/share/jupyter/runtime/kernel-515b4e2f-033d-41a9-934f-471f4b3125d7.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib64/python3.6/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m             \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1767\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_UNRECOGNIZED_ARGS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[0;31m# consume any positionals following the last Optional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1975\u001b[0;31m         \u001b[0mstop_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsume_positionals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/argparse.py\u001b[0m in \u001b[0;36mconsume_positionals\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0mstart_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0marg_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m                 \u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/argparse.py\u001b[0m in \u001b[0;36mtake_action\u001b[0;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[1;32m   1823\u001b[0m             \u001b[0mseen_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1824\u001b[0;31m             \u001b[0margument_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margument_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/argparse.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, action, arg_strings)\u001b[0m\n\u001b[1;32m   2278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2279\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_strings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2280\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/argparse.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2279\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_strings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2280\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/argparse.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, action, arg_string)\u001b[0m\n\u001b[1;32m   2306\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid %(type)s value: %(value)r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2307\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument num_trials: invalid int value: '/home/scitech/.local/share/jupyter/runtime/kernel-515b4e2f-033d-41a9-934f-471f4b3125d7.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-50d4f9e8d341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-50d4f9e8d341>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0margs\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mN_TRIALS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1734\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1735\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1772\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2392\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2393\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib64/python3.6/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2379\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2380\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2036\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m   2037\u001b[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0;32m-> 2038\u001b[0;31m                                                                      value))\n\u001b[0m\u001b[1;32m   2039\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \"\"\"\n\u001b[0;32m--> 823\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     chained_exceptions_tb_offset, context)\n\u001b[1;32m    701\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mchained_exception_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 + out_list)\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "def hpo_monitor_sigterm(final_prefix = \"\"):\n",
    "    joblib.dump(STUDY,final_prefix + \"hpo_study_checkpoint_\" + MODEL + \".pkl\")\n",
    "    \n",
    "def main():\n",
    "    global MODEL\n",
    "    global EPOCHS\n",
    "    global CHECKPOINTS_FILES_LIST\n",
    "    global TAR_FILE\n",
    "    global N_TRIALS\n",
    "\n",
    "    try:\n",
    "#         signal.signal(signal.SIGTERM, sigterm_handler)\n",
    "        \n",
    "        args     = parser.parse_args()\n",
    "        N_TRIALS = args.trials[0]\n",
    "        MODEL = \"vgg16\"\n",
    "        hpo_checkpoint_file = \"hpo_study_checkpoint_\" + MODEL + \".pkl\"\n",
    "        create_study(hpo_checkpoint_file)\n",
    "\n",
    "    except Exception as e:\n",
    "    \tpass\n",
    "#     finally:\n",
    "#         hpo_monitor_sigterm(\"final_\")\n",
    "#     return 0\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished = 0\n",
    "while finished != N_TRIALS:\n",
    "    STUDY = joblib.load(\"hpo_study_checkpoint_\" + MODEL + \".pkl\")\n",
    "    todo_trials = N_TRIALS - len(STUDY.trials_dataframe())\n",
    "    if todo_trials > 0 :\n",
    "        STUDY.optimize(objective, n_trials=todo_trials, timeout=600, callbacks=[hpo_monitor])\n",
    "        finished += 1\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "def hpo_monitor(study, trial):\n",
    "    joblib.dump(study,\"hpo_study_checkpoint_\" + MODEL + \".pkl\")\n",
    "    \n",
    "def create_study(hpo_checkpoint_file):\n",
    "    global STUDY\n",
    "    STUDY = joblib.load(\"hpo_study_checkpoint_\" + MODEL + \".pkl\")\n",
    "    \n",
    "    if STUDY == None:\n",
    "        finished = 1\n",
    "    else:\n",
    "        finished = len(STUDY.trials_dataframe()\n",
    "\n",
    "    if finished < N_Trials:\n",
    "        STUDY = joblib.load(\"hpo_study_checkpoint_\" + MODEL + \".pkl\")\n",
    "        todo_trials = N_TRIALS - finished)\n",
    "        if todo_trials > 0 :\n",
    "            STUDY.optimize(objective, n_trials=todo_trials, timeout=600, callbacks=[hpo_monitor])\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "#         STUDY = optuna.create_study(direction = 'maximize', study_name = MODEL)\n",
    "        STUDY = OptKeras.create_study(study_name=MODEL,monitor='val_acc',direction='maximize')\n",
    "        STUDY.optimize(objective, n_trials=N_TRIALS, timeout=600, callbacks=[hpo_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'neptune' has no attribute 'init'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-55bf629ea67a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mneptunecontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitoring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptuna\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopt_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mneptune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jakub-czakon/blog-hpo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mneptune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'optuna sweep'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'neptune' has no attribute 'init'"
     ]
    }
   ],
   "source": [
    "import neptune\n",
    "import neptunecontrib.monitoring.optuna as opt_utils\n",
    "\n",
    "neptune.init('jakub-czakon/blog-hpo')\n",
    "neptune.create_experiment(name='optuna sweep')\n",
    "\n",
    "monitor = opt_utils.NeptuneMonitor()\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100, callbacks=[monitor])\n",
    "opt_utils.log_study(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neptune-cli in /usr/local/lib/python3.6/site-packages (2.8.23)\n",
      "Collecting neptune-contrib\n",
      "  Downloading neptune-contrib-0.24.0.tar.gz (64 kB)\n",
      "     |████████████████████████████████| 64 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: GitPython>=2.0.8 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (3.1.8)\n",
      "Requirement already satisfied: terminaltables<3.0.0,>=2.1.0 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (2.1.0)\n",
      "Requirement already satisfied: kitchen>=1.2.4 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (1.2.6)\n",
      "Requirement already satisfied: more-itertools>=4.1.0 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (8.5.0)\n",
      "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (2.24.0)\n",
      "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (0.18.2)\n",
      "Requirement already satisfied: pykwalify<1.6.0,>=1.5.2 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (1.5.2)\n",
      "Requirement already satisfied: websocket-client>=0.35.0 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (0.57.0)\n",
      "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (7.352.0)\n",
      "Requirement already satisfied: Flask==0.12.0 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (0.12)\n",
      "Requirement already satisfied: humanize>=0.5.1 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (2.6.0)\n",
      "Requirement already satisfied: Pillow>=1.7.6 in /usr/local/lib64/python3.6/site-packages (from neptune-cli) (7.2.0)\n",
      "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (1.1.10)\n",
      "Requirement already satisfied: raven>=6.1.0 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (6.10.0)\n",
      "Requirement already satisfied: pathlib2==2.3.0 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (2.3.0)\n",
      "Requirement already satisfied: tqdm>=4.11.2 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (4.48.2)\n",
      "Requirement already satisfied: voluptuous>=0.9.3 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (0.11.7)\n",
      "Requirement already satisfied: argcomplete>=1.9.3 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (1.12.0)\n",
      "Requirement already satisfied: PyJWT>=1.5.2 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (1.7.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.8.0 in /usr/local/lib/python3.6/site-packages (from neptune-cli) (1.3.0)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib64/python3.6/site-packages (from neptune-cli) (5.7.2)\n",
      "Collecting attrdict>=2.0.0\n",
      "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Collecting neptune-client>=0.4.110\n",
      "  Downloading neptune-client-0.4.119.tar.gz (90 kB)\n",
      "     |████████████████████████████████| 90 kB 3.9 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.13 in /usr/local/lib/python3.6/site-packages (from neptune-contrib) (0.16.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib64/python3.6/site-packages (from neptune-contrib) (1.1.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib64/python3.6/site-packages (from neptune-contrib) (3.3.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/site-packages (from GitPython>=2.0.8->neptune-cli) (4.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests>=2.11.1->neptune-cli) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests>=2.11.1->neptune-cli) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests>=2.11.1->neptune-cli) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3.6/site-packages (from requests>=2.11.1->neptune-cli) (2.7)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /usr/lib64/python3.6/site-packages (from pykwalify<1.6.0,>=1.5.2->neptune-cli) (3.13)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/site-packages (from pykwalify<1.6.0,>=1.5.2->neptune-cli) (0.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.6/site-packages (from pykwalify<1.6.0,>=1.5.2->neptune-cli) (2.8.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3.6/site-packages (from websocket-client>=0.35.0->neptune-cli) (1.14.0)\n",
      "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.6/site-packages (from Flask==0.12.0->neptune-cli) (1.1.0)\n",
      "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.6/site-packages (from Flask==0.12.0->neptune-cli) (7.1.2)\n",
      "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.6/site-packages (from Flask==0.12.0->neptune-cli) (2.11.2)\n",
      "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.6/site-packages (from Flask==0.12.0->neptune-cli) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<2,>=0.23; python_version == \"3.6\" in /usr/local/lib/python3.6/site-packages (from argcomplete>=1.9.3->neptune-cli) (1.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/site-packages (from requests-oauthlib>=0.8.0->neptune-cli) (3.1.0)\n",
      "Collecting bravado\n",
      "  Downloading bravado-10.6.2-py2.py3-none-any.whl (37 kB)\n",
      "Collecting py3nvml\n",
      "  Downloading py3nvml-0.2.6-py3-none-any.whl (55 kB)\n",
      "     |████████████████████████████████| 55 kB 4.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/site-packages (from neptune-client>=0.4.110->neptune-contrib) (20.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib64/python3.6/site-packages (from pandas->neptune-contrib) (1.19.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas->neptune-contrib) (2020.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/site-packages (from matplotlib->neptune-contrib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/site-packages (from matplotlib->neptune-contrib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib64/python3.6/site-packages (from matplotlib->neptune-contrib) (1.2.0)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/site-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-cli) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib64/python3.6/site-packages (from Jinja2>=2.4->Flask==0.12.0->neptune-cli) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/site-packages (from importlib-metadata<2,>=0.23; python_version == \"3.6\"->argcomplete>=1.9.3->neptune-cli) (3.1.0)\n",
      "Collecting simplejson\n",
      "  Downloading simplejson-3.17.2-cp36-cp36m-manylinux2010_x86_64.whl (127 kB)\n",
      "     |████████████████████████████████| 127 kB 21.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.6/site-packages (from bravado->neptune-client>=0.4.110->neptune-contrib) (3.7.4.3)\n",
      "Collecting msgpack-python\n",
      "  Downloading msgpack-python-0.5.6.tar.gz (138 kB)\n",
      "     |████████████████████████████████| 138 kB 17.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting monotonic\n",
      "  Downloading monotonic-1.5-py2.py3-none-any.whl (5.3 kB)\n",
      "Collecting bravado-core>=5.16.1\n",
      "  Downloading bravado_core-5.17.0-py2.py3-none-any.whl (67 kB)\n",
      "     |████████████████████████████████| 67 kB 7.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting xmltodict\n",
      "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting swagger-spec-validator>=2.0.1\n",
      "  Downloading swagger_spec_validator-2.7.3-py2.py3-none-any.whl (27 kB)\n",
      "Collecting jsonref\n",
      "  Downloading jsonref-0.2-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: jsonschema[format]>=2.5.1 in /usr/local/lib/python3.6/site-packages (from bravado-core>=5.16.1->bravado->neptune-client>=0.4.110->neptune-contrib) (3.2.0)\n",
      "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib64/python3.6/site-packages (from bravado-core>=5.16.1->bravado->neptune-client>=0.4.110->neptune-contrib) (1.0.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/site-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client>=0.4.110->neptune-contrib) (20.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib64/python3.6/site-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client>=0.4.110->neptune-contrib) (0.16.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/site-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client>=0.4.110->neptune-contrib) (50.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting strict-rfc3339; extra == \"format\"\n",
      "  Downloading strict-rfc3339-0.7.tar.gz (17 kB)\n",
      "Collecting jsonpointer>1.13; extra == \"format\"\n",
      "  Downloading jsonpointer-2.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting webcolors; extra == \"format\"\n",
      "  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n",
      "Collecting rfc3987; extra == \"format\"\n",
      "  Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\n",
      "Building wheels for collected packages: neptune-contrib, neptune-client, msgpack-python, strict-rfc3339\n",
      "  Building wheel for neptune-contrib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for neptune-contrib: filename=neptune_contrib-0+unknown-py3-none-any.whl size=77523 sha256=73ac3558ff876c5b3587cb9f04098980156c8246b385e61713b47519b4691b95\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/13/05/e2a2aa31e5fd73a26536765a8a3014aa87b313ee141878f3c8\n",
      "  Building wheel for neptune-client (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for neptune-client: filename=neptune_client-0.4.119-py2.py3-none-any.whl size=150018 sha256=c5ae1cf94101b404ac540fc930b306049506b890668f7b9a59121b935dcbe804\n",
      "  Stored in directory: /root/.cache/pip/wheels/0c/89/27/eb0f1475ebb29351a79e017cc4e6b42607f77c17d8267a6578\n",
      "  Building wheel for msgpack-python (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for msgpack-python: filename=msgpack_python-0.5.6-cp36-cp36m-linux_x86_64.whl size=311832 sha256=d002832017063ec351c307d81c0de4521a8e3f7e39ba2c7317b2d8a17ea21537\n",
      "  Stored in directory: /root/.cache/pip/wheels/d5/bc/14/cd44eeb567de86911dd5ca37e718e67044d03b6128eb80ef1b\n",
      "  Building wheel for strict-rfc3339 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for strict-rfc3339: filename=strict_rfc3339-0.7-py3-none-any.whl size=18119 sha256=796c236b9bba916489150a6d437d01498768215d5f67162f5cfdc490e9ddebef\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/8f/86/00a0ce6029db25cbd4c6d7d57498175ca8e93ab48286f3b277\n",
      "Successfully built neptune-contrib neptune-client msgpack-python strict-rfc3339\n",
      "Installing collected packages: attrdict, simplejson, msgpack-python, monotonic, swagger-spec-validator, jsonref, bravado-core, bravado, xmltodict, py3nvml, neptune-client, neptune-contrib, strict-rfc3339, jsonpointer, webcolors, rfc3987\n",
      "Successfully installed attrdict-2.0.1 bravado-10.6.2 bravado-core-5.17.0 jsonpointer-2.0 jsonref-0.2 monotonic-1.5 msgpack-python-0.5.6 neptune-client-0.4.119 neptune-contrib-0+unknown py3nvml-0.2.6 rfc3987-1.3.8 simplejson-3.17.2 strict-rfc3339-0.7 swagger-spec-validator-2.7.3 webcolors-1.11.1 xmltodict-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!sudo pip3 install neptune-cli neptune-contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "optkeras.optkeras.get_trial_default = lambda: optuna.trial.FrozenTrial(\n",
    "            None, None, None, None, None, None, None, None, None, None, None)\n",
    "study_name = \"CatsAndDogs\" + '_Simple'\n",
    "ok = OptKeras(study_name=study_name,\n",
    "              monitor='val_acc',\n",
    "              direction='maximize')\n",
    "import joblib\n",
    "MODEL = \"vgg\"\n",
    "CHECKPOINTS_FILES_LIST = []\n",
    "STUDY = None\n",
    "N_TRIALS = 5\n",
    "# checkpoint_path = \"cp-{epoch:04d}.ckpt\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Binary Classification of Images with Different Architectures')\n",
    "parser.add_argument('trials',  metavar='num_trials', type=int, nargs=1, help = \"number of HPO trials\")\n",
    "\n",
    "def sigterm_handler(signum, frame):\n",
    "    hpo_monitor_sigterm()\n",
    "    sys.exit(3)\n",
    "    \n",
    "def hpo_monitor(study, trial):\n",
    "    joblib.dump(study,\"hpo_study_checkpoint_\" + MODEL + \".pkl\")\n",
    "    \n",
    "def hpo_monitor_sigterm(final_prefix = \"\"):\n",
    "    joblib.dump(STUDY,final_prefix + \"hpo_study_checkpoint_\" + MODEL + \".pkl\")\n",
    "    \n",
    "def objective(trial):\n",
    "    nb_classes = 2\n",
    "    epochs=3\n",
    "    batch_size =2\n",
    "    optimizer_options = [\"RMSprop\", \"Adam\", \"SGD\"]\n",
    "\n",
    "    vgg16_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "    x = vgg16_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation=trial.suggest_categorical('activation', ['relu', 'linear']))(x)\n",
    "    predictions = Dense(nb_classes, activation = 'softmax')(x)\n",
    "    model = Model(input = vgg16_model.input, output = predictions)\n",
    "    for layer in vgg16_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer = trial.suggest_categorical(\"optimizer\", [\"rmsprop\", \"Adam\", \"SGD\"]),loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    period=10)\n",
    "    model.fit(x=train_photos, y=train_labels,batch_size=2 , epochs=epochs, callbacks=ok.callbacks(trial),\n",
    "              verbose=ok.keras_verbose ,validation_data=(val_photos,val_labels))\n",
    "    return ok.trial_best_value\n",
    "\n",
    "def check_status_last_trial():\n",
    "    global STUDY\n",
    "    last_trial_index = len(STUDY.trials) -1\n",
    "    last_trial_status = str(STUDY.trials[last_trial_index].state)\n",
    "    \n",
    "def create_study(finished,hpo_checkpoint_file):\n",
    "    global STUDY\n",
    "    if finished < N_TRIALS:\n",
    "        STUDY = joblib.load(\"hpo_study_checkpoint_\" + MODEL + \".pkl\")\n",
    "        todo_trials = N_TRIALS - len(STUDY.trials_dataframe())\n",
    "        if todo_trials > 0 :\n",
    "            STUDY.optimize(objective, n_trials=todo_trials, timeout=600, callbacks=[hpo_monitor])\n",
    "            finished += 1\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        STUDY = optuna.create_study(direction = 'maximize', study_name = MODEL)\n",
    "        STUDY.optimize(objective, n_trials=N_TRIALS, timeout=600, callbacks=[hpo_monitor])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
