{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-20.2.3-py2.py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras==2.1.5\n",
      "  Downloading Keras-2.1.5-py2.py3-none-any.whl (334 kB)\n",
      "\u001b[K     |████████████████████████████████| 334 kB 9.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow==1.13.1\n",
      "  Downloading tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 92.5 MB 20.0 MB/s eta 0:00:01   |▎                               | 808 kB 5.0 MB/s eta 0:00:19     |███▉                            | 11.2 MB 5.6 MB/s eta 0:00:15     |████████████▏                   | 35.2 MB 36.1 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 617 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.1.2-cp36-cp36m-manylinux1_x86_64.whl (10.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.5 MB 26.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow\n",
      "  Downloading Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 12.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting optuna\n",
      "  Downloading optuna-2.1.0.tar.gz (232 kB)\n",
      "\u001b[K     |████████████████████████████████| 232 kB 19.3 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scikit-image\n",
      "  Downloading scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting optkeras\n",
      "  Downloading optkeras-0.0.7-py3-none-any.whl (6.9 kB)\n",
      "Collecting scipy>=0.14\n",
      "  Downloading scipy-1.5.2-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pyyaml in /usr/lib64/python3.6/site-packages (from keras==2.1.5) (3.13)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/lib/python3.6/site-packages (from keras==2.1.5) (1.14.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.1.6\n",
      "  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 21.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 36.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0\n",
      "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 29.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
      "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
      "\u001b[K     |████████████████████████████████| 367 kB 29.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.6.1\n",
      "  Downloading protobuf-3.13.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel>=0.26\n",
      "  Using cached wheel-0.35.1-py2.py3-none-any.whl (33 kB)\n",
      "Collecting gast>=0.2.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas) (2020.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 4.1 MB/s eta 0:00:01    |▎                               | 51 kB 3.9 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting alembic\n",
      "  Downloading alembic-1.4.3-py2.py3-none-any.whl (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 26.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cmaes>=0.6.0\n",
      "  Downloading cmaes-0.6.1-py3-none-any.whl (9.7 kB)\n",
      "Collecting joblib\n",
      "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "\u001b[K     |████████████████████████████████| 300 kB 30.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.50.0-py2.py3-none-any.whl (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 15.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-4.2.1-py2.py3-none-any.whl (14 kB)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.4.0-py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 10.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.6/site-packages (from optuna) (20.4)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.3.19-cp36-cp36m-manylinux2010_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 21.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio>=2.3.0\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.0\n",
      "  Downloading networkx-2.5-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib!=3.0.0,>=2.0.0\n",
      "  Downloading matplotlib-3.3.2-cp36-cp36m-manylinux1_x86_64.whl (11.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.6 MB 31.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 37.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py\n",
      "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 4.1 MB/s eta 0:00:01     |██████▉                         | 614 kB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mock>=2.0.0\n",
      "  Downloading mock-4.0.2-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (39.2.0)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.3-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PrettyTable<0.8,>=0.7.2\n",
      "  Downloading prettytable-0.7.2.tar.bz2 (21 kB)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.1.0 in /usr/local/lib/python3.6/site-packages (from cliff->optuna) (2.4.7)\n",
      "Collecting cmd2!=0.8.3,>=0.8.0\n",
      "  Downloading cmd2-1.3.10-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 35.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.2.2-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.5.0-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 37.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 17.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: certifi>=2020.06.20 in /usr/local/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2020.6.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.9.2 in /usr/local/lib64/python3.6/site-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=16.3.0 in /usr/local/lib/python3.6/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (20.1.0)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.0.tar.gz (16 kB)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth>=0.1.7 in /usr/local/lib/python3.6/site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
      "Collecting colorama>=0.3.7\n",
      "  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.1.0)\n",
      "Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for termcolor, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for PrettyTable, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for pyperclip, since package 'wheel' is not installed.\n",
      "Building wheels for collected packages: optuna\n",
      "  Building wheel for optuna (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for optuna: filename=optuna-2.1.0-py3-none-any.whl size=321090 sha256=073d4452c1c7ae9e504091782416663cbcc087874840aab036ee78363fb0e3f6\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/13/e3/e2c767339ab685a3fae35e10741b5c4345369a901352cc8d5a\n",
      "Successfully built optuna\n",
      "Installing collected packages: pip, numpy, scipy, keras, termcolor, h5py, keras-applications, absl-py, grpcio, astor, markdown, werkzeug, wheel, protobuf, tensorboard, mock, tensorflow-estimator, keras-preprocessing, gast, tensorflow, pandas, pillow, joblib, threadpoolctl, scikit-learn, sklearn, python-editor, sqlalchemy, Mako, alembic, cmaes, tqdm, colorlog, PrettyTable, pyperclip, colorama, cmd2, pbr, stevedore, cliff, optuna, imageio, networkx, PyWavelets, kiwisolver, cycler, matplotlib, tifffile, scikit-image, optkeras\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.2.2\n",
      "    Uninstalling pip-20.2.2:\n",
      "      Successfully uninstalled pip-20.2.2\n",
      "    Running setup.py install for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for PrettyTable ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for pyperclip ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed Mako-1.1.3 PrettyTable-0.7.2 PyWavelets-1.1.1 absl-py-0.10.0 alembic-1.4.3 astor-0.8.1 cliff-3.4.0 cmaes-0.6.1 cmd2-1.3.10 colorama-0.4.3 colorlog-4.2.1 cycler-0.10.0 gast-0.4.0 grpcio-1.32.0 h5py-2.10.0 imageio-2.9.0 joblib-0.16.0 keras-2.1.5 keras-applications-1.0.8 keras-preprocessing-1.1.2 kiwisolver-1.2.0 markdown-3.2.2 matplotlib-3.3.2 mock-4.0.2 networkx-2.5 numpy-1.19.2 optkeras-0.0.7 optuna-2.1.0 pandas-1.1.2 pbr-5.5.0 pillow-7.2.0 pip-20.2.3 protobuf-3.13.0 pyperclip-1.8.0 python-editor-1.0.4 scikit-image-0.17.2 scikit-learn-0.23.2 scipy-1.5.2 sklearn-0.0 sqlalchemy-1.3.19 stevedore-3.2.2 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 threadpoolctl-2.1.0 tifffile-2020.9.3 tqdm-4.50.0 werkzeug-1.0.1 wheel-0.35.1\n"
     ]
    }
   ],
   "source": [
    "!sudo pip3 install --upgrade pip keras==2.1.5 tensorflow==1.13.1 numpy pandas pillow sklearn optuna scikit-image  optkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Pegasus.api.workflow.Workflow at 0x7f514c1bd1d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import requests \n",
    "from glob import glob\n",
    "from zipfile import ZipFile\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "#Import Pegasus API\n",
    "from Pegasus.api import *\n",
    "\n",
    "#Properties\n",
    "props = Properties()\n",
    "props[\"dagman.retry\"] = \"100\"\n",
    "props[\"pegasus.transfer.arguments\"] = \"-m 1\"\n",
    "props.write()\n",
    "\n",
    "#Replica Catalog\n",
    "rc = ReplicaCatalog()\n",
    "input_files = glob('*.jpg')\n",
    "input_files.sort()\n",
    "in_files=[]\n",
    "\n",
    "checkpoint_file = \"checkpoint_file.hdf5\"\n",
    "if not os.path.isfile(checkpoint_file):\n",
    "    df = pd.DataFrame(list())\n",
    "    df.to_csv(checkpoint_file)\n",
    "    \n",
    "    \n",
    "for file in input_files:\n",
    "    in_files.append(File(file))\n",
    "    rc.add_replica(\"local\", File(file), str(Path(\".\").resolve() / file))  \n",
    "rc.add_replica(\"local\", checkpoint_file, Path(\".\").resolve() / checkpoint_file)\n",
    "rc.write()\n",
    "\n",
    "\n",
    "#Transformation\n",
    "pre_process_resize = Transformation( \"preprocess1.py\",\n",
    "        site = \"local\",\n",
    "        pfn = \"/home/scitech/shared-data/CatsAndDogs/preprocess1.py\",\n",
    "        is_stageable=True)\n",
    "\n",
    "pre_process_augment = Transformation( \"Augmentation.py\",\n",
    "        site = \"local\",\n",
    "        pfn = \"/home/scitech/shared-data/CatsAndDogs/Augmentation.py\",\n",
    "        is_stageable=True)\n",
    "\n",
    "data_split  = Transformation( \"Data_Split.py\",\n",
    "        site = \"local\",\n",
    "        pfn = \"/home/scitech/shared-data/CatsAndDogs/Data_Split.py\",\n",
    "        is_stageable=True)\n",
    "\n",
    "vgg_model  = Transformation( \"VGG_model.py\",\n",
    "        site = \"local\",\n",
    "        pfn = \"/home/scitech/shared-data/CatsAndDogs/VGG_model.py\",\n",
    "        is_stageable=True)\n",
    "                    \n",
    "tc = TransformationCatalog()\\\n",
    "    .add_transformations(pre_process_resize,pre_process_augment,data_split,vgg_model)\\\n",
    "    .write()\n",
    "\n",
    "#Workflow\n",
    "wf = Workflow(\"Cats_and_Dogs\", infer_dependencies=True)\n",
    "\n",
    "\n",
    "resized_images = File('resized_images.txt')\n",
    "all_files = [File(\"resized_{}\".format(f.lfn)) for f in in_files]\n",
    "labels = File('labels.txt')\n",
    "\n",
    "job_preprocess1 = Job(pre_process_resize)\\\n",
    "                    .add_inputs(*in_files)\\\n",
    "                    .add_outputs(*all_files,resized_images,labels) \n",
    "\n",
    "aug_images_txt = File('augmentation.txt')\n",
    "aug_labels_txt = File('aug_labels.txt')\n",
    "augmented_files = []\n",
    "for f in all_files:\n",
    "    augmented_files.extend([File(str(f).replace(\"{}\".format(os.path.splitext(str(f))[0]), \"Aug_{}_{}\".format(os.path.splitext(str(f))[0],i))) for i in range(3)])\n",
    "\n",
    "    \n",
    "job_preprocess2 = Job(pre_process_augment)\\\n",
    "                    .add_inputs(*all_files,labels)\\\n",
    "                    .add_outputs(aug_images_txt,aug_labels_txt,*augmented_files)\n",
    "\n",
    "training_data = File('training.pkl')\n",
    "testing_data = File('testing.pkl')\n",
    "val_data = File('validation.pkl')\n",
    "\n",
    "job_data_split = Job(data_split)\\\n",
    "                    .add_inputs(*augmented_files,labels)\\\n",
    "                    .add_outputs(training_data,testing_data,val_data)\n",
    "\n",
    "model = File('model.h5')\n",
    "csv_log = File(\"model_history_log.csv\")\n",
    "\n",
    "job_vgg_model = Job(vgg_model)\\\n",
    "                    .add_checkpoint(File(checkpoint_file), stage_out=True)\\\n",
    "                    .add_inputs(*augmented_files,training_data,testing_data,val_data)\\\n",
    "                    .add_profiles(Namespace.PEGASUS, key=\"maxwalltime\", value=1)\\\n",
    "                    .add_outputs(model,csv_log)\n",
    "\n",
    "wf.add_jobs(job_preprocess1,job_preprocess2,job_data_split,job_vgg_model)                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "################\n",
      "# pegasus-plan #\n",
      "################\n",
      "[main] WARN  schema.JsonMetaSchema  - Unknown keyword $defs - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword\n",
      "[main] WARN  schema.JsonMetaSchema  - Unknown keyword additionalItems - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword\n",
      "[main] WARN  schema.JsonMetaSchema  - Unknown keyword examples - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword\n",
      "2020.10.01 09:36:40.867 UTC:\n",
      "2020.10.01 09:36:40.872 UTC:   -----------------------------------------------------------------------\n",
      "2020.10.01 09:36:40.878 UTC:   File for submitting this DAG to HTCondor           : Cats_and_Dogs-0.dag.condor.sub\n",
      "2020.10.01 09:36:40.883 UTC:   Log of DAGMan debugging messages                 : Cats_and_Dogs-0.dag.dagman.out\n",
      "2020.10.01 09:36:40.889 UTC:   Log of HTCondor library output                     : Cats_and_Dogs-0.dag.lib.out\n",
      "2020.10.01 09:36:40.894 UTC:   Log of HTCondor library error messages             : Cats_and_Dogs-0.dag.lib.err\n",
      "2020.10.01 09:36:40.900 UTC:   Log of the life of condor_dagman itself          : Cats_and_Dogs-0.dag.dagman.log\n",
      "2020.10.01 09:36:40.905 UTC:\n",
      "2020.10.01 09:36:40.911 UTC:   -no_submit given, not submitting DAG to HTCondor.  You can do this with:\n",
      "2020.10.01 09:36:40.922 UTC:   -----------------------------------------------------------------------\n",
      "2020.10.01 09:36:41.676 UTC:   Your database is compatible with Pegasus version: 5.0.0dev\n",
      "2020.10.01 09:36:42.688 UTC:   Created Pegasus database in: sqlite:////home/scitech/shared-data/CatsAndDogs/scitech/pegasus/Cats_and_Dogs/run0001/Cats_and_Dogs-0.replicas.db\n",
      "2020.10.01 09:36:42.694 UTC:   Your database is compatible with Pegasus version: 5.0.0dev\n",
      "2020.10.01 09:36:42.749 UTC:   Output replica catalog set to jdbc:sqlite:/home/scitech/shared-data/CatsAndDogs/scitech/pegasus/Cats_and_Dogs/run0001/Cats_and_Dogs-0.replicas.db\n",
      "2020.10.01 09:36:42.935 UTC:   Submitting to condor Cats_and_Dogs-0.dag.condor.sub\n",
      "2020.10.01 09:36:42.958 UTC:\n",
      "2020.10.01 09:36:42.963 UTC:   Your workflow has been started and is running in the base directory:\n",
      "2020.10.01 09:36:42.969 UTC:\n",
      "2020.10.01 09:36:42.975 UTC:   /home/scitech/shared-data/CatsAndDogs/scitech/pegasus/Cats_and_Dogs/run0001\n",
      "2020.10.01 09:36:42.981 UTC:\n",
      "2020.10.01 09:36:42.986 UTC:   *** To monitor the workflow you can run ***\n",
      "2020.10.01 09:36:42.991 UTC:\n",
      "2020.10.01 09:36:42.997 UTC:   pegasus-status -l /home/scitech/shared-data/CatsAndDogs/scitech/pegasus/Cats_and_Dogs/run0001\n",
      "2020.10.01 09:36:43.002 UTC:\n",
      "2020.10.01 09:36:43.008 UTC:   *** To remove your workflow run ***\n",
      "2020.10.01 09:36:43.013 UTC:\n",
      "2020.10.01 09:36:43.018 UTC:   pegasus-remove /home/scitech/shared-data/CatsAndDogs/scitech/pegasus/Cats_and_Dogs/run0001\n",
      "2020.10.01 09:36:43.701 UTC:   Time taken to execute is 3.199 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32m######################################\u001b[0m------------]  76.0% ..Running (\u001b[1;32mCompleted: 19\u001b[0m, \u001b[1;33mQueued: 0\u001b[0m, \u001b[1;36mRunning: 1\u001b[0m, \u001b[1;31mFailed: 0\u001b[0m)"
     ]
    }
   ],
   "source": [
    "try:\n",
    "     wf.plan(submit=True)\\\n",
    "        .wait()\\\n",
    "        .analyze()\\\n",
    "        .statistics()\n",
    "except PegasusClientError as e:\n",
    "    print(e.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
