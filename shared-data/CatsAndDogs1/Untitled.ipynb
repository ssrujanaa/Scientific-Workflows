{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:84: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 432 samples, validate on 48 samples\n",
      "Epoch 1/3\n",
      "432/432 [==============================] - 69s 159ms/step - loss: 8.0234 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/3\n",
      "432/432 [==============================] - 76s 176ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/3\n",
      "432/432 [==============================] - 74s 172ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "120/120 [==============================] - 19s 154ms/step\n",
      "Test Loss: 8.059047758579254\n",
      "Test Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[83]:\n",
    "\n",
    "\n",
    "import pickle\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input,Dense,BatchNormalization,Flatten,Dropout,GlobalAveragePooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import layer_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model,load_model\n",
    "\n",
    "with open('training.pkl', 'rb') as f:\n",
    "     train = pickle.load(f)\n",
    "    \n",
    "with open('testing.pkl', 'rb') as f:\n",
    "     test = pickle.load(f)\n",
    "        \n",
    "with open('validation.pkl','rb') as f:\n",
    "    val = pickle.load(f)\n",
    "\n",
    "train_photos, train_labels = list(), list()\n",
    "tp = list()\n",
    "for file in train:\n",
    "    if 'Cat' in file:\n",
    "        output = 1.0\n",
    "    else:\n",
    "        output = 0.0\n",
    "    photo = load_img(file)\n",
    "    photo = img_to_array(photo)\n",
    "    train_photos.append(photo)\n",
    "    train_labels.append(output)\n",
    "train_photos = asarray(train_photos)\n",
    "train_labels = asarray(train_labels)\n",
    "\n",
    "test_photos, test_labels = list(), list()\n",
    "for file in test:\n",
    "    if 'Cat' in file:\n",
    "        output = 1.0\n",
    "    else:\n",
    "        output = 0.0\n",
    "    photo = load_img(file)\n",
    "    photo = img_to_array(photo)\n",
    "    tp.append(photo)\n",
    "    test_photos.append(photo)\n",
    "    test_labels.append(output)\n",
    "test_photos = asarray(test_photos)\n",
    "test_labels = asarray(test_labels)\n",
    "\n",
    "val_photos, val_labels = list(), list()\n",
    "for file in val:\n",
    "    if 'Cat' in file:\n",
    "        output = 1.0\n",
    "    else:\n",
    "        output = 0.0\n",
    "    photo = load_img(file)\n",
    "    photo = img_to_array(photo)\n",
    "    val_photos.append(photo)\n",
    "    val_labels.append(output)\n",
    "val_photos = asarray(val_photos)\n",
    "val_labels = asarray(val_labels)\n",
    "\n",
    "nb_classes = 2\n",
    "epochs=3\n",
    "batch_size =2\n",
    "\n",
    "vgg16_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "x = vgg16_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(nb_classes, activation = 'softmax')(x)\n",
    "model = Model(input = vgg16_model.input, output = predictions)\n",
    "\n",
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(optimizer = 'rmsprop',loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model_info = model.fit(x=train_photos, y=train_labels,batch_size=2 , epochs=epochs, \n",
    "                   verbose=1,validation_data=(val_photos,val_labels))\n",
    "\n",
    "model.save('model.h5.tar.gz')\n",
    "model.save('model.h5')\n",
    "\n",
    "m= load_model(\"model.h5\")\n",
    "test_photos = test_photos.astype(\"float32\")\n",
    "\n",
    "results = m.evaluate(test_photos, test_labels, batch_size=1)\n",
    "print(\"Test Loss:\", results[0])\n",
    "print(\"Test Accuracy:\", results[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m= load_model(\"model.h5\")\n",
    "test_photos = test_photos.astype(\"float32\")\n",
    "\n",
    "results = m.evaluate(test_photos, test_labels, batch_size=1)\n",
    "print(\"Test Loss:\", results[0])\n",
    "print(\"Test Accuracy:\", results[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
